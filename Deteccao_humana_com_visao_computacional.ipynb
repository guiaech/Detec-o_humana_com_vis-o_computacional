{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deteccao_humana_com_visao_computacional.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNOLpYXqORWVJTUOYatdsPC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guiaech/Deteccao_humana_com_visao_computacional/blob/main/Deteccao_humana_com_visao_computacional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Projeto Python - Detecção e contagem humana em tempo real**\n",
        "Neste projeto python, iremos construir o Sistema de Detecção e Contagem Humana através da Webcam ou você pode fornecer seu próprio vídeo ou imagens. Este é um projeto de aprendizado profundo."
      ],
      "metadata": {
        "id": "0UG08CGRh2OQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Pré-requisitos do projeto**\n",
        "\n",
        "**OpenCV:**  uma biblioteca forte usada para aprendizado de máquina\n",
        "\n",
        "**Imutils:** processamento da imagem\n",
        "\n",
        "**Numpy:**  usado para computação científica. A imagem é armazenada em uma matriz numpy.\n",
        "\n",
        "**Argparse:**  usado para fornecer entrada na linha de comando."
      ],
      "metadata": {
        "id": "pvGSK_Shf7tA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82vcUcd5e54f",
        "outputId": "f2eda301-057e-401f-caf6-59721a742bd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.7/dist-packages (0.5.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n"
          ]
        }
      ],
      "source": [
        "#INSTALANDO AS BIBLIOTECAS NECESSÁRIAS\n",
        "!pip install opencv-python\n",
        "!pip install imutils\n",
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Histograma do Descritor de Gradiente Orientado**\n",
        "HOG é um descritor de recurso usado em visão computacional e processamento de imagem para fins de detecção de objetos. Esta é uma das técnicas mais populares para detecção de objetos, para nossa sorte, o OpenCV já foi implementado de forma eficiente para combinar o algoritmo HOG Descriptor com Support Vector Machine ou SVM."
      ],
      "metadata": {
        "id": "RzewNblFhxZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#IMPORTANDO AS BIBLIOTECAS\n",
        "import cv2\n",
        "import imutils\n",
        "import numpy as np\n",
        "import argparse"
      ],
      "metadata": {
        "id": "ELJnpN8shDeg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Criando um modelo que detectará Humanos:**\n",
        "\n",
        "Conforme discutido anteriormente, usaremos HOGDescriptor com SVM já implementado no OpenCV. O código abaixo fará este trabalho:\n",
        "\n",
        "**cv2.HOGDescriptor_getDefaultPeopleDetector()** chama o modelo pré-treinado para detecção humana de OpenCV e então alimentaremos nossa máquina de vetores de suporte com ele."
      ],
      "metadata": {
        "id": "nDHFlNAmiE7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HOGCV = cv2.HOGDescriptor()\n",
        "HOGCV.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())"
      ],
      "metadata": {
        "id": "GzWQxmXwfiA_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Detect() method:**\n",
        "\n",
        "Aqui, a mágica real acontecerá.\n",
        "\n",
        "**Vídeo:** um vídeo combina uma sequência de imagens para formar uma imagem em movimento. Chamamos essas imagens de Frame. Portanto, em geral, detectaremos a pessoa no quadro. E mostre um após o outro que parece um vídeo.\n",
        "\n",
        "Isso é exatamente o que nosso método Detect () fará. Será necessário um quadro para detectar uma pessoa nela. Faça uma caixa ao redor de uma pessoa e mostre a moldura ... e devolva a moldura com a pessoa delimitada por uma caixa verde.\n",
        "\n",
        "\n",
        "Tudo será feito por detectMultiScale(). Ele retorna 2 tuplas.\n",
        "\n",
        "Lista contendo coordenadas da caixa delimitadora de pessoa.\n",
        "As coordenadas estão na forma X, Y, W, H.\n",
        "Onde x, y são as coordenadas iniciais da caixa ew, h são a largura e a altura da caixa, respectivamente.\n",
        "Valor de confiança de que é uma pessoa."
      ],
      "metadata": {
        "id": "Q_6Z0rW-jT0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect(frame):\n",
        "    bounding_box_cordinates, weights =  HOGCV.detectMultiScale(frame, winStride = (4, 4), padding = (8, 8), scale = 1.03)\n",
        "    \n",
        "    person = 1\n",
        "    for x,y,w,h in bounding_box_cordinates:\n",
        "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 2)\n",
        "        cv2.putText(frame, f'person {person}', (x,y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1)\n",
        "        person += 1\n",
        "    \n",
        "    cv2.putText(frame, 'Status : Detecting ', (40,40), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255,0,0), 2)\n",
        "    cv2.putText(frame, f'Total Persons : {person-1}', (40,70), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255,0,0), 2)\n",
        "    cv2.imshow('output', frame)\n",
        "\n",
        "    return frame"
      ],
      "metadata": {
        "id": "pnAdF1o_g8cY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Método HumanDetector ()**\n",
        "\n",
        "Existem duas maneiras de obter vídeo.\n",
        "\n",
        "Câmera web\n",
        "\n",
        "Caminho do arquivo armazenado\n",
        "Neste projeto de aprendizado profundo, podemos tirar fotos também. Portanto, nosso método irá verificar se um caminho é fornecido e, em seguida, procurar o vídeo ou imagem no caminho fornecido e operar. Caso contrário, a webCam será aberta."
      ],
      "metadata": {
        "id": "LmeK2cWmkvm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def humanDetector(args):\n",
        "    image_path = args[\"image\"]\n",
        "    video_path = args['video']\n",
        "    if str(args[\"camera\"]) == 'true' : camera = True \n",
        "    else : camera = False\n",
        "\n",
        "    writer = None\n",
        "    if args['output'] is not None and image_path is None:\n",
        "        writer = cv2.VideoWriter(args['output'],cv2.VideoWriter_fourcc(*'MJPG'), 10, (600,600))\n",
        "\n",
        "    if camera:\n",
        "        print('[INFO] Opening Web Cam.')\n",
        "        detectByCamera(ouput_path,writer)\n",
        "    elif video_path is not None:\n",
        "        print('[INFO] Opening Video from path.')\n",
        "        detectByPathVideo(video_path, writer)\n",
        "    elif image_path is not None:\n",
        "        print('[INFO] Opening Image from path.')\n",
        "        detectByPathImage(image_path, args['output'])"
      ],
      "metadata": {
        "id": "WMeM4d1Kjj0K"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Método DetectByCamera ()**\n",
        "\n",
        "cv2.VideoCapture (0) passando 0 nesta função significa que queremos gravar de uma webcam. video.read () lê quadro a quadro. Ele retorna uma marca de verificação que é Verdadeira se isso foi capaz de ler um quadro de outra forma False.\n",
        "Agora, para cada quadro, chamaremos o método detect (). Em seguida, escrevemos o quadro em nosso arquivo de saída."
      ],
      "metadata": {
        "id": "L8UMpzFIlHfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detectByCamera(writer):   \n",
        "    video = cv2.VideoCapture(0)\n",
        "    print('Detecting people...')\n",
        "\n",
        "    while True:\n",
        "        check, frame = video.read()\n",
        "\n",
        "        frame = detect(frame)\n",
        "        if writer is not None:\n",
        "            writer.write(frame)\n",
        "\n",
        "        key = cv2.waitKey(1)\n",
        "        if key == ord('q'):\n",
        "            break\n",
        "\n",
        "    video.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "vDeOP8pelRlB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9eNgGqSZlWdo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}