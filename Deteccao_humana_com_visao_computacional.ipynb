{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deteccao_humana_com_visao_computacional.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMSZM+5mPMFujFvyg8LjvIo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guiaech/Deteccao_humana_com_visao_computacional/blob/main/Deteccao_humana_com_visao_computacional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Projeto Python - Detecção e contagem humana em tempo real**\n",
        "Neste projeto python, iremos construir o Sistema de Detecção e Contagem Humana através da Webcam ou você pode fornecer seu próprio vídeo ou imagens. Este é um projeto de aprendizado profundo."
      ],
      "metadata": {
        "id": "0UG08CGRh2OQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Pré-requisitos do projeto**\n",
        "\n",
        "**OpenCV:**  uma biblioteca forte usada para aprendizado de máquina\n",
        "\n",
        "**Imutils:** processamento da imagem\n",
        "\n",
        "**Numpy:**  usado para computação científica. A imagem é armazenada em uma matriz numpy.\n",
        "\n",
        "**Argparse:**  usado para fornecer entrada na linha de comando."
      ],
      "metadata": {
        "id": "pvGSK_Shf7tA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82vcUcd5e54f",
        "outputId": "f2eda301-057e-401f-caf6-59721a742bd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.7/dist-packages (0.5.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n"
          ]
        }
      ],
      "source": [
        "#INSTALANDO AS BIBLIOTECAS NECESSÁRIAS\n",
        "!pip install opencv-python\n",
        "!pip install imutils\n",
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Histograma do Descritor de Gradiente Orientado**\n",
        "HOG é um descritor de recurso usado em visão computacional e processamento de imagem para fins de detecção de objetos. Esta é uma das técnicas mais populares para detecção de objetos, para nossa sorte, o OpenCV já foi implementado de forma eficiente para combinar o algoritmo HOG Descriptor com Support Vector Machine ou SVM."
      ],
      "metadata": {
        "id": "RzewNblFhxZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#IMPORTANDO AS BIBLIOTECAS\n",
        "import cv2\n",
        "import imutils\n",
        "import numpy as np\n",
        "import argparse"
      ],
      "metadata": {
        "id": "ELJnpN8shDeg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Criando um modelo que detectará Humanos:**\n",
        "\n",
        "Conforme discutido anteriormente, usaremos HOGDescriptor com SVM já implementado no OpenCV. O código abaixo fará este trabalho:\n",
        "\n",
        "**cv2.HOGDescriptor_getDefaultPeopleDetector()** chama o modelo pré-treinado para detecção humana de OpenCV e então alimentaremos nossa máquina de vetores de suporte com ele."
      ],
      "metadata": {
        "id": "nDHFlNAmiE7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HOGCV = cv2.HOGDescriptor()\n",
        "HOGCV.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())"
      ],
      "metadata": {
        "id": "GzWQxmXwfiA_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Detect() method:**\n",
        "\n",
        "Aqui, a mágica real acontecerá.\n",
        "\n",
        "**Vídeo:** um vídeo combina uma sequência de imagens para formar uma imagem em movimento. Chamamos essas imagens de Frame. Portanto, em geral, detectaremos a pessoa no quadro. E mostre um após o outro que parece um vídeo.\n",
        "\n",
        "Isso é exatamente o que nosso método Detect () fará. Será necessário um quadro para detectar uma pessoa nela. Faça uma caixa ao redor de uma pessoa e mostre a moldura ... e devolva a moldura com a pessoa delimitada por uma caixa verde.\n",
        "\n",
        "\n",
        "Tudo será feito por detectMultiScale(). Ele retorna 2 tuplas.\n",
        "\n",
        "Lista contendo coordenadas da caixa delimitadora de pessoa.\n",
        "As coordenadas estão na forma X, Y, W, H.\n",
        "Onde x, y são as coordenadas iniciais da caixa ew, h são a largura e a altura da caixa, respectivamente.\n",
        "Valor de confiança de que é uma pessoa."
      ],
      "metadata": {
        "id": "Q_6Z0rW-jT0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect(frame):\n",
        "    bounding_box_cordinates, weights =  HOGCV.detectMultiScale(frame, winStride = (4, 4), padding = (8, 8), scale = 1.03)\n",
        "    \n",
        "    person = 1\n",
        "    for x,y,w,h in bounding_box_cordinates:\n",
        "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 2)\n",
        "        cv2.putText(frame, f'person {person}', (x,y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1)\n",
        "        person += 1\n",
        "    \n",
        "    cv2.putText(frame, 'Status : Detecting ', (40,40), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255,0,0), 2)\n",
        "    cv2.putText(frame, f'Total Persons : {person-1}', (40,70), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255,0,0), 2)\n",
        "    cv2.imshow('output', frame)\n",
        "\n",
        "    return frame"
      ],
      "metadata": {
        "id": "pnAdF1o_g8cY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Método HumanDetector ()**\n",
        "\n",
        "Existem duas maneiras de obter vídeo.\n",
        "\n",
        "Câmera web\n",
        "\n",
        "Caminho do arquivo armazenado\n",
        "Neste projeto de aprendizado profundo, podemos tirar fotos também. Portanto, nosso método irá verificar se um caminho é fornecido e, em seguida, procurar o vídeo ou imagem no caminho fornecido e operar. Caso contrário, a webCam será aberta."
      ],
      "metadata": {
        "id": "LmeK2cWmkvm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def humanDetector(args):\n",
        "    image_path = args[\"image\"]\n",
        "    video_path = args['video']\n",
        "    if str(args[\"camera\"]) == 'true' : camera = True \n",
        "    else : camera = False\n",
        "\n",
        "    writer = None\n",
        "    if args['output'] is not None and image_path is None:\n",
        "        writer = cv2.VideoWriter(args['output'],cv2.VideoWriter_fourcc(*'MJPG'), 10, (600,600))\n",
        "\n",
        "    if camera:\n",
        "        print('[INFO] Opening Web Cam.')\n",
        "        detectByCamera(ouput_path,writer)\n",
        "    elif video_path is not None:\n",
        "        print('[INFO] Opening Video from path.')\n",
        "        detectByPathVideo(video_path, writer)\n",
        "    elif image_path is not None:\n",
        "        print('[INFO] Opening Image from path.')\n",
        "        detectByPathImage(image_path, args['output'])"
      ],
      "metadata": {
        "id": "WMeM4d1Kjj0K"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Método DetectByCamera ()**\n",
        "\n",
        "cv2.VideoCapture (0) passando 0 nesta função significa que queremos gravar de uma webcam. video.read () lê quadro a quadro. Ele retorna uma marca de verificação que é Verdadeira se isso foi capaz de ler um quadro de outra forma False.\n",
        "Agora, para cada quadro, chamaremos o método detect (). Em seguida, escrevemos o quadro em nosso arquivo de saída."
      ],
      "metadata": {
        "id": "L8UMpzFIlHfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detectByCamera(writer):   \n",
        "    video = cv2.VideoCapture(0)\n",
        "    print('Detecting people...')\n",
        "\n",
        "    while True:\n",
        "        check, frame = video.read()\n",
        "\n",
        "        frame = detect(frame)\n",
        "        if writer is not None:\n",
        "            writer.write(frame)\n",
        "\n",
        "        key = cv2.waitKey(1)\n",
        "        if key == ord('q'):\n",
        "            break\n",
        "\n",
        "    video.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "vDeOP8pelRlB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Método DetectByPathVideo ()**\n",
        "\n",
        "Este método é muito semelhante ao método anterior, exceto que forneceremos um caminho para o Vídeo. Primeiro, verificamos se o vídeo no caminho fornecido foi encontrado ou não.\n",
        "\n",
        "Nota - um caminho completo deve ser fornecido\n",
        "\n",
        "A implementação é semelhante à função anterior, exceto para cada quadro, verificaremos se ele lê o quadro com êxito ou não. No final, quando o quadro não for lido, encerraremos o loop."
      ],
      "metadata": {
        "id": "SP-Gc8hJm1aT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detectByPathVideo(path, writer):\n",
        "\n",
        "    video = cv2.VideoCapture(path)\n",
        "    check, frame = video.read()\n",
        "    if check == False:\n",
        "        print('Vídeo não encontrado. Digite um caminho válido (o caminho completo do vídeo deve ser fornecido).')\n",
        "        return\n",
        "\n",
        "    print('Detectando pessoas ...' )\n",
        "    while video.isOpened():\n",
        "        \n",
        "        check, frame =  video.read()\n",
        "\n",
        "        if check:\n",
        "            frame = imutils.resize(frame , width=min(800,frame.shape[1]))\n",
        "            frame = detect(frame)\n",
        "            \n",
        "            if writer is not None:\n",
        "                writer.write(frame)\n",
        "            \n",
        "            key = cv2.waitKey(1)\n",
        "            if key== ord('q'):\n",
        "                break\n",
        "        else:\n",
        "            break\n",
        "    video.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "def detectByCamera(writer):   \n",
        "    video = cv2.VideoCapture(0)\n",
        "    print('Detectando pessoas ...' )\n",
        "\n",
        "    while True:\n",
        "        check, frame = video.read()\n",
        "\n",
        "        frame = detect(frame)\n",
        "        if writer is not None:\n",
        "            writer.write(frame)\n",
        "\n",
        "        key = cv2.waitKey(1)\n",
        "        if key == ord('q'):\n",
        "                break\n",
        "\n",
        "    video.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "9eNgGqSZlWdo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Método DetectByPathimage ()**\n",
        "\n",
        "Este método é usado se uma pessoa precisa ser detectada a partir de uma imagem."
      ],
      "metadata": {
        "id": "e8As8Bn_n7aJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detectByPathImage(path, output_path):\n",
        "    image = cv2.imread(path)\n",
        "\n",
        "    image = imutils.resize(image, width = min(800, image.shape[1])) \n",
        "\n",
        "    result_image = detect(image)\n",
        "\n",
        "    if output_path is not None:\n",
        "        cv2.imwrite(output_path, result_image)\n",
        "\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "fHkgYjkVoItL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Método Argparse ()**\n",
        "\n",
        "A função argparse () simplesmente analisa e retorna como um dicionário os argumentos passados ​​pelo seu terminal para o nosso script. Haverá três argumentos no analisador:\n",
        "\n",
        "**Imagem:** o caminho para o arquivo de imagem dentro de seu sistema\n",
        "\n",
        "**Vídeo:** o caminho para o arquivo de vídeo em seu sistema\n",
        "\n",
        "**Câmera:** uma variável que se configurada como 'true' chamará o método cameraDetect ()."
      ],
      "metadata": {
        "id": "zQxS59_DoPJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def argsParser():\n",
        "    arg_parse = argparse.ArgumentParser()\n",
        "    arg_parse.add_argument(\"-v\", \"--video\", default=None, help=\"path to Video File \")\n",
        "    arg_parse.add_argument(\"-i\", \"--image\", default=None, help=\"path to Image File \")\n",
        "    arg_parse.add_argument(\"-c\", \"--camera\", default=False, help=\"Set true if you want to use the camera.\")\n",
        "    arg_parse.add_argument(\"-o\", \"--output\", type=str, help=\"path to optional output video file\")\n",
        "    args = vars(arg_parse.parse_args())\n",
        "\n",
        "    return args"
      ],
      "metadata": {
        "id": "d8I4rNJhoWTa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Função principal**\n",
        "\n",
        "Chegamos ao final do nosso projeto.\n",
        "\n",
        "Em vez de declarar nosso modelo acima, podemos declará-lo em nossa função principal."
      ],
      "metadata": {
        "id": "d-MbSkB1oZd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    HOGCV = cv2.HOGDescriptor()\n",
        "    HOGCV.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
        "\n",
        "    args = argsParser()\n",
        "    humanDetector(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "9yP8LYbzog6Z",
        "outputId": "ef503aa7-3a54-412a-8b26-251abcd98dff"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] [-v VIDEO] [-i IMAGE] [-c CAMERA]\n",
            "                             [-o OUTPUT]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-ff071b61-87d1-4d5e-bf46-6eb668995fbf.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    }
  ]
}